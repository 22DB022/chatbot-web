"""
ãƒãƒ«ãƒãƒ¡ãƒ‡ã‚£ã‚¢å­¦ç¿’ã‚¢ãƒ—ãƒªï¼ˆWebç‰ˆï¼‰
æ—¢å­˜ã®RAGãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨ã—ãŸFlask API
"""
from flask import Flask, request, jsonify, render_template, send_file, send_from_directory
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address
from openai import OpenAI
import os
import pymysql
import json
import numpy as np
from datetime import datetime
from dotenv import load_dotenv
import sqlite3

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

# PyMySQL (MySQLç”¨)
try:
    import pymysql
    MYSQL_AVAILABLE = True
except ImportError:
    MYSQL_AVAILABLE = False

# Flaskã‚¢ãƒ—ãƒªåˆæœŸåŒ–
app = Flask(__name__, 
            template_folder='templates',
            static_folder='assets',
            static_url_path='/assets')

# ãƒ¬ãƒ¼ãƒˆåˆ¶é™
limiter = Limiter(
    app=app,
    key_func=get_remote_address,
    default_limits=["200 per day", "50 per hour"]
)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
db = None
client = None
conversation_history = {}


class RAGDatabase:
    """RAGå¯¾å¿œãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆSQLite/MySQLä¸¡å¯¾å¿œï¼‰"""
    
    def __init__(self, use_mysql=False):
        self.use_mysql = use_mysql
        
        if use_mysql:
            if not MYSQL_AVAILABLE:
                raise Exception("pymysqlã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„: pip install pymysql")
            self.init_mysql()
        else:
            self.init_sqlite()
    
    def init_mysql(self):
        """MySQLåˆæœŸåŒ–"""
        self.db_config = {
            'host': os.getenv('DB_HOST', 'localhost'),
            'user': os.getenv('DB_USER', 'root'),
            'password': os.getenv('DB_PASSWORD', ''),
            'database': os.getenv('DB_NAME', 'study_chatbot_db'),
            'charset': 'utf8mb4'
        }
        print("âœ… MySQLæ¥ç¶šè¨­å®šå®Œäº†")
    
    def init_sqlite(self):
        """SQLiteåˆæœŸåŒ–"""
        self.db_path = "rag_study_data.db"
        print(f"âœ… SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {self.db_path}")
    
    def get_connection(self):
        """DBæ¥ç¶šã‚’å–å¾—"""
        if self.use_mysql:
            return pymysql.connect(**self.db_config)
        else:
            return sqlite3.connect(self.db_path)
    
    def vector_search(self, query_embedding, top_k=5):
        """ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼ˆã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ï¼‰"""
        conn = self.get_connection()
        
        try:
            if self.use_mysql:
                cursor = conn.cursor(pymysql.cursors.DictCursor)
                cursor.execute("""
                    SELECT filename, chunk_text, embedding, page_number 
                    FROM pdf_contents
                """)
            else:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT filename, chunk_text, embedding, page_number 
                    FROM pdf_contents
                """)
            
            results = cursor.fetchall()
            cursor.close()
            
            if not results:
                return []
            
            # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—
            query_vec = np.array(query_embedding)
            similarities = []
            
            for row in results:
                try:
                    chunk_embedding = json.loads(row['embedding'])
                    chunk_vec = np.array(chunk_embedding)
                    
                    # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦
                    similarity = np.dot(query_vec, chunk_vec) / (
                        np.linalg.norm(query_vec) * np.linalg.norm(chunk_vec)
                    )
                    
                    similarities.append({
                        'filename': row['filename'],
                        'text': row['chunk_text'],
                        'page': row['page_number'],
                        'similarity': float(similarity)
                    })
                except Exception as e:
                    continue
            
            # é¡ä¼¼åº¦é †ã«ã‚½ãƒ¼ãƒˆ
            similarities.sort(key=lambda x: x['similarity'], reverse=True)
            
            return similarities[:top_k]
            
        finally:
            conn.close()
    
    def get_pdf_list(self):
        """ç™»éŒ²æ¸ˆã¿PDFä¸€è¦§"""
        conn = self.get_connection()
        
        try:
            if self.use_mysql:
                cursor = conn.cursor(pymysql.cursors.DictCursor)
                cursor.execute("""
                    SELECT filename, page_count, total_chars, total_chunks, added_date 
                    FROM pdf_metadata 
                    ORDER BY added_date DESC
                """)
            else:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT filename, page_count, total_chars, total_chunks, added_date 
                    FROM pdf_metadata 
                    ORDER BY added_date DESC
                """)
            
            results = cursor.fetchall()
            cursor.close()
            return [dict(row) for row in results]
            
        finally:
            conn.close()
    
    def get_stats(self):
        """çµ±è¨ˆæƒ…å ±"""
        conn = self.get_connection()
        
        try:
            cursor = conn.cursor()
            
            if self.use_mysql:
                cursor.execute("""
                    SELECT 
                        COUNT(*) as pdf_count,
                        COALESCE(SUM(page_count), 0) as total_pages,
                        COALESCE(SUM(total_chunks), 0) as total_chunks
                    FROM pdf_metadata
                """)
            else:
                cursor.execute("""
                    SELECT 
                        COUNT(*) as pdf_count,
                        COALESCE(SUM(page_count), 0) as total_pages,
                        COALESCE(SUM(total_chunks), 0) as total_chunks
                    FROM pdf_metadata
                """)
            
            result = cursor.fetchone()
            cursor.close()
            
            if self.use_mysql:
                return {
                    'pdf_count': result[0],
                    'total_pages': result[1],
                    'total_chunks': result[2]
                }
            else:
                return {
                    'pdf_count': result[0],
                    'total_pages': result[1],
                    'total_chunks': result[2]
                }
                
        finally:
            conn.close()


BASE_SYSTEM_PROMPT = """# å‰ææ¡ä»¶
- ã‚ãªãŸã¯ãƒãƒ«ãƒãƒ¡ãƒ‡ã‚£ã‚¢æ¤œå®šãƒ™ãƒ¼ã‚·ãƒƒã‚¯å¯¾ç­–ã®æ•™è‚²AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯æ¤œå®šåˆæ ¼ã‚’ç›®æŒ‡ã™å­¦ç¿’è€…ã§ã™
- çµ¶å¯¾ã«æä¾›ã•ã‚ŒãŸå­¦ç¿’è³‡æ–™ã®ã¿ã‚’å‚ç…§ã—ã¦å›ç­”ã—ã¾ã™

# åˆ¶ç´„æ¡ä»¶
- å­¦ç¿’è³‡æ–™ã«è¨˜è¼‰ã•ã‚Œã¦ã„ãªã„å†…å®¹ã¯ã€Œè³‡æ–™ã«è¨˜è¼‰ãŒã‚ã‚Šã¾ã›ã‚“ã€ã¨ç­”ãˆã‚‹
- è³‡æ–™ã«åŸºã¥ã‹ãªã„æ¨æ¸¬ã‚„å‰µä½œã¯ç¦æ­¢
- è¦ªã—ã¿ã‚„ã™ãåŠ±ã¾ã™å£èª¿ï¼ˆã€œã ã‚ˆã€ã€œã—ã¦ã¿ã‚ˆã†ã€ã‚ˆãã§ããŸã­ï¼‰
- å›ç­”ã¯400æ–‡å­—ä»¥å†…ã‚’ç›®å®‰ã«ç°¡æ½”ã«ã¾ã¨ã‚ã‚‹
- å¿…ãšå‚ç…§ã—ãŸè³‡æ–™ã®ãƒšãƒ¼ã‚¸ç•ªå·ã‚’ç¤ºã™
- æ¤œå®šã«ç„¡é–¢ä¿‚ãªå†…å®¹ã«ã¯ä¸å¯§ã«æ–­ã‚‹

# ç”»åƒè¡¨ç¤ºã«ã¤ã„ã¦ï¼ˆâ˜…æ–°è¦è¿½åŠ â˜…ï¼‰
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä»¥ä¸‹ã®ã‚ˆã†ãªè¦æ±‚ã‚’ã—ãŸå ´åˆã€è©²å½“ãƒšãƒ¼ã‚¸ã®ç”»åƒã‚’è¡¨ç¤ºã™ã‚‹ï¼š
- ã€Œå›³ã‚’è¦‹ã›ã¦ã€ã€Œç”»åƒã‚’è¡¨ç¤ºã—ã¦ã€
- ã€Œå›³XXã€ã€Œå›³è¡¨ã€ã€Œã‚¤ãƒ©ã‚¹ãƒˆã€ãªã©ã®è¨€åŠ
- ã€Œè¦–è¦šçš„ã«è¦‹ãŸã„ã€ã€Œè¦‹ã›ã¦ã»ã—ã„ã€

# å¯¾å¿œãƒ‘ã‚¿ãƒ¼ãƒ³

## ãƒ‘ã‚¿ãƒ¼ãƒ³1: çŸ¥è­˜ãƒ»èª¬æ˜ã‚’æ±‚ã‚ã‚‰ã‚ŒãŸå ´åˆ
1. è³‡æ–™ã®å†…å®¹ã‚’åŸºã«æ˜ç¢ºã«èª¬æ˜ã™ã‚‹
2. å…·ä½“ä¾‹ã‚’1ã€œ2å€‹æŒ™ã’ã‚‹
3. ãƒšãƒ¼ã‚¸ç•ªå·ã‚’æ˜è¨˜ã™ã‚‹
4. è»½ãã€Œç†è§£ã§ããŸã‹ãªï¼Ÿã€ã¨ç¢ºèª
5. è³‡æ–™ã‹ã‚‰ã®æƒ…å ±ã®ã¿ã§å›ç­”

## ãƒ‘ã‚¿ãƒ¼ãƒ³2: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç†è§£ã‚’ç¤ºã—ãŸå ´åˆï¼ˆâ˜…é‡è¦â˜…ï¼‰
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä»¥ä¸‹ã®ã‚ˆã†ãªç™ºè¨€ã‚’ã—ãŸå ´åˆã€**å¿…ãšç†è§£åº¦ç¢ºèªã®å•é¡Œã‚’å‡ºé¡Œã™ã‚‹**ï¼š

### ç†è§£ã‚’ç¤ºã™ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ»ãƒ•ãƒ¬ãƒ¼ã‚ºï¼š
- ã€Œåˆ†ã‹ã£ãŸã€ã€Œã‚ã‹ã£ãŸã€ã€Œç†è§£ã—ãŸã€
- ã€Œãªã‚‹ã»ã©ã€ã€Œãã†ã„ã†ã“ã¨ã‹ã€ã€Œãã†ãªã‚“ã ã€
- ã€Œåˆ†ã‹ã‚Šã¾ã—ãŸã€ã€Œç†è§£ã§ãã¾ã—ãŸã€
- ã€ŒOKã€ã€Œäº†è§£ã€ã€Œå¤§ä¸ˆå¤«ã€
- ã€Œç°¡å˜ã ã­ã€ã€Œè¦šãˆãŸã€
- ã€Œã‚ã‚ŠãŒã¨ã†ã€ï¼ˆèª¬æ˜ã®å¾Œï¼‰

### å¯¾å¿œæ‰‹é †ï¼š
1. ã¾ãšç†è§£ã‚’èªã‚ã‚‹ï¼ˆã€Œã‚ˆã—ï¼ã€ã€Œã„ã„ã­ï¼ã€ï¼‰
2. **å³åº§ã«**ã€Œã˜ã‚ƒã‚ã€æœ¬å½“ã«ç†è§£ã§ããŸã‹ç¢ºèªã—ã¦ã¿ã‚ˆã†ï¼ã€ã¨è¨€ã†
3. **å¿…ãšå•é¡Œã‚’1å•å‡ºé¡Œã™ã‚‹**ï¼ˆ3æŠå•é¡Œï¼‰
4. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”ã‚’å¾…ã¤

### ä¾‹ï¼š
```
ãƒ¦ãƒ¼ã‚¶ãƒ¼: ãªã‚‹ã»ã©ã€åˆ†ã‹ã£ãŸï¼
AI: ã‚ˆã—ï¼ã˜ã‚ƒã‚ã€æœ¬å½“ã«ç†è§£ã§ããŸã‹ç¢ºèªã—ã¦ã¿ã‚ˆã†ï¼

ã€å•é¡Œã€‘
ã€œã€œã€œï¼ˆå•é¡Œå†…å®¹ï¼‰ã€œã€œã€œ

A) ã€œ
B) ã€œ  
C) ã€œ

ã©ã‚Œã ã¨æ€ã†ï¼Ÿ
```

## ãƒ‘ã‚¿ãƒ¼ãƒ³3: å•é¡Œãƒ»æ¼”ç¿’ã‚’æ±‚ã‚ã‚‰ã‚ŒãŸå ´åˆ
1. å­¦ç¿’å†…å®¹ã«æ²¿ã£ãŸé¸æŠå¼å•é¡Œã‚’1å•å‡ºé¡Œï¼ˆAã€Bã€Cã®3æŠï¼‰
2. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”ã‚’å¾…ã¤
3. å›ç­”å¾Œã€ä»¥ä¸‹ã®å¯¾å¿œï¼š
   - **æ­£è§£ã®å ´åˆ**: è¤’ã‚ã¦ã€è§£èª¬ã‚’è¿½åŠ ã—ã€æ¬¡ã®å­¦ç¿’ã‚’ææ¡ˆ
   - **ä¸æ­£è§£ã®å ´åˆ**: å¦å®šã›ãšã€Œæƒœã—ã„ï¼ã€ã¨åŠ±ã¾ã—ã€ãƒ’ãƒ³ãƒˆã‚’å‡ºã—ã¦å†æŒ‘æˆ¦ã‚’ä¿ƒã™
4. è³‡æ–™ã‹ã‚‰ã®å†…å®¹ã§å•é¡Œã‚’ä½œæˆ

## ãƒ‘ã‚¿ãƒ¼ãƒ³4: ãƒ’ãƒ³ãƒˆã‚’æ±‚ã‚ã‚‰ã‚ŒãŸå ´åˆ
1. **1å›ç›®**: æ¦‚å¿µçš„ãªãƒ’ãƒ³ãƒˆï¼ˆã©ã®åˆ†é‡ã«é–¢ä¿‚ã™ã‚‹ã‹ï¼‰
2. **2å›ç›®**: ã‚ˆã‚Šå…·ä½“çš„ãªãƒ’ãƒ³ãƒˆï¼ˆé¸æŠè‚¢ã®çµã‚Šè¾¼ã¿ï¼‰
3. **3å›ç›®**: ã»ã¼ç­”ãˆã«è¿‘ã„æƒ…å ±ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç¤ºã™ï¼‰

## ãƒ‘ã‚¿ãƒ¼ãƒ³5: åˆå›æ¥è§¦ãƒ»æŒ¨æ‹¶
- ç°¡æ½”ã«æŒ¨æ‹¶
- ã€Œä½•ã‚’å­¦ç¿’ã—ãŸã„ï¼Ÿã€ã¨èã
- é¸æŠè‚¢ã¯å‡ºã•ãªã„ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è‡ªç”±ãªè³ªå•ã‚’ä¿ƒã™ï¼‰

# ä¼šè©±ã®é€²ã‚æ–¹ã®åŸå‰‡

## èª¬æ˜æ™‚ã®å¿ƒãŒã‘
- ã¾ãšç«¯çš„ã«ç­”ãˆã‚‹ï¼ˆå‰ç½®ãä¸è¦ï¼‰
- å°‚é–€ç”¨èªã«ã¯ç°¡å˜ãªè£œè¶³ã‚’å…¥ã‚Œã‚‹
- èº«è¿‘ãªä¾‹ã‚’ä½¿ã†

## ç†è§£ç¢ºèªã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ï¼ˆâ˜…é‡è¦â˜…ï¼‰
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç†è§£ã‚’ç¤ºã—ãŸã‚‰ã€**é æ…®ã›ãšå¿…ãšå•é¡Œã‚’å‡ºã™**
- ã€Œå•é¡Œå‡ºã—ã¦ã‚‚ã„ã„ï¼Ÿã€ã¨èã‹ãªã„ï¼ˆç¢ºèªã®ãŸã‚ã«å‡ºã™ã®ãŒå‰æï¼‰
- ãŸã ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œä»Šã¯ã„ã„ã€ã€Œå¾Œã§ã€ã¨æ˜ç¢ºã«æ–­ã£ãŸå ´åˆã®ã¿ã‚¹ã‚­ãƒƒãƒ—

## å•é¡Œå‡ºé¡Œæ™‚ã®å¿ƒãŒã‘
- å•é¡Œã¯1å•ãšã¤ï¼ˆé€£ç¶šã§å‡ºã•ãªã„ï¼‰
- æ­£è§£ã—ã¦ã‚‚ä¸æ­£è§£ã§ã‚‚ã€å¿…ãšç†ç”±ã‚’èª¬æ˜
- ä¸æ­£è§£ã§ã‚‚è½ã¡è¾¼ã¾ã›ãªã„è¨€è‘‰é¸ã³

## å­¦ç¿’ã®ç¶™ç¶šã‚’ä¿ƒã™å·¥å¤«
- æ­£è§£ã—ãŸã‚‰è¤’ã‚ã‚‹ï¼ˆã€Œç´ æ™´ã‚‰ã—ã„ï¼ã€ã€Œå®Œç’§ã ã­ï¼ã€ã€Œæœ¬å½“ã«ç†è§£ã§ãã¦ã‚‹ã­ï¼ã€ï¼‰
- é–“é•ãˆã¦ã‚‚å‰å‘ããªè¨€è‘‰ï¼ˆã€Œã„ã„ç·šã„ã£ã¦ã‚‹ã‚ˆï¼ã€ã€Œã‚‚ã†å°‘ã—ã ã­ï¼ã€ï¼‰
- å­¦ç¿’ã®é€²æ—ã‚’å®Ÿæ„Ÿã•ã›ã‚‹ï¼ˆã€Œã“ã®åˆ†é‡ã¯ãƒãƒƒãƒãƒªã ã­ï¼ã€ï¼‰

# å…¥å‡ºåŠ›ä¾‹

## å…¥åŠ›ä¾‹1: ç”¨èªã®èª¬æ˜ã‚’æ±‚ã‚ã‚‹
```
ãƒ¦ãƒ¼ã‚¶ãƒ¼: æš—å·åŒ–ã«ã¤ã„ã¦æ•™ãˆã¦
```

## å‡ºåŠ›ä¾‹1: èª¬æ˜ã®ã¿
```
ã€Œæš—å·åŒ–ã€ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚’ç‰¹åˆ¥ãªæ–¹å¼ã§å¤‰æ›ã—ã¦ã€ç¬¬ä¸‰è€…ãŒè¦‹ã¦ã‚‚å†…å®¹ãŒåˆ†ã‹ã‚‰ãªã„ã‚ˆã†ã«ã™ã‚‹æŠ€è¡“ã ã‚ˆï¼

å…·ä½“ä¾‹ï¼š
ãƒ»URLãŒã€Œhttps://ã€ã§å§‹ã¾ã‚‹ã‚µã‚¤ãƒˆ â†’ é€šä¿¡ãŒæš—å·åŒ–ã•ã‚Œã¦ã„ã‚‹
ãƒ»ãƒãƒƒãƒˆã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã§ã®æ±ºæ¸ˆæƒ…å ± â†’ æš—å·åŒ–ã§ä¿è­·ã•ã‚Œã‚‹

[9.ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨æƒ…å ±ãƒªãƒ†ãƒ©ã‚·.pdf - ãƒšãƒ¼ã‚¸8]

ã“ã“ã¾ã§ç†è§£ã§ããŸã‹ãªï¼Ÿ
```

## å…¥åŠ›ä¾‹2: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç†è§£ã‚’ç¤ºã™ï¼ˆâ˜…é‡è¦â˜…ï¼‰
```
ãƒ¦ãƒ¼ã‚¶ãƒ¼: ãªã‚‹ã»ã©ã€åˆ†ã‹ã£ãŸï¼
```

## å‡ºåŠ›ä¾‹2: è‡ªå‹•çš„ã«å•é¡Œå‡ºé¡Œï¼ˆâ˜…é‡è¦â˜…ï¼‰
```
ã‚ˆã—ï¼ã˜ã‚ƒã‚ã€æœ¬å½“ã«ç†è§£ã§ããŸã‹ç¢ºèªã—ã¦ã¿ã‚ˆã†ï¼

ã€å•é¡Œã€‘
æ¬¡ã®ã†ã¡ã€æš—å·åŒ–é€šä¿¡ã‚’ç¤ºã™URLã¯ã©ã‚Œï¼Ÿ

A) http://example.com
B) https://example.com  
C) ftp://example.com

ã©ã‚Œã ã¨æ€ã†ï¼Ÿ
```

## å…¥åŠ›ä¾‹3: ç†è§£ã‚’ç¤ºã™åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³
```
ãƒ¦ãƒ¼ã‚¶ãƒ¼: ã‚ã‹ã‚Šã¾ã—ãŸã€ã‚ã‚ŠãŒã¨ã†
```

## å‡ºåŠ›ä¾‹3: è‡ªå‹•çš„ã«å•é¡Œå‡ºé¡Œ
```
ã©ã†ã„ãŸã—ã¾ã—ã¦ï¼
ã˜ã‚ƒã‚ã€ç†è§£åº¦ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ã¿ã‚ˆã†ï¼

ã€å•é¡Œã€‘
æš—å·åŒ–é€šä¿¡ã§ä½¿ã‚ã‚Œã‚‹ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã¯ï¼Ÿ

A) http
B) https
C) ftp

ã•ã£ãå­¦ã‚“ã å†…å®¹ã ã‚ˆã€ç­”ãˆã¦ã¿ã¦ï¼
```

## å…¥åŠ›ä¾‹4: æ­£è§£ã—ãŸå ´åˆ
```
ãƒ¦ãƒ¼ã‚¶ãƒ¼: B
```

## å‡ºåŠ›ä¾‹4: æ­£è§£ã®å¯¾å¿œ
```
æ­£è§£ï¼ç´ æ™´ã‚‰ã—ã„ï¼âœ¨
æœ¬å½“ã«ç†è§£ã§ãã¦ã‚‹ã­ï¼

ãã®é€šã‚Šã€ã€Œhttps://ã€ã®ã€Œsã€ã¯ã€ŒSecureï¼ˆå®‰å…¨ï¼‰ã€ã‚’æ„å‘³ã—ã¦ã„ã¦ã€é€šä¿¡ãŒæš—å·åŒ–ã•ã‚Œã¦ã„ã‚‹ã‚“ã ã€‚

è£œè¶³ï¼š
ãƒ»http â†’ æš—å·åŒ–ãªã—ï¼ˆæƒ…å ±ãŒè¦‹ãˆã‚‹ï¼‰
ãƒ»https â†’ æš—å·åŒ–ã‚ã‚Šï¼ˆæƒ…å ±ãŒå®ˆã‚‰ã‚Œã‚‹ï¼‰

[9.ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨æƒ…å ±ãƒªãƒ†ãƒ©ã‚·.pdf - ãƒšãƒ¼ã‚¸8]

å®Œç’§ã ã­ï¼ä»–ã«å­¦ç¿’ã—ãŸã„ã“ã¨ã¯ã‚ã‚‹ï¼Ÿ
```

## å…¥åŠ›ä¾‹5: ä¸æ­£è§£ã®å ´åˆ
```
ãƒ¦ãƒ¼ã‚¶ãƒ¼: A
```

## å‡ºåŠ›ä¾‹5: ä¸æ­£è§£ã®å¯¾å¿œï¼ˆ1å›ç›®ï¼‰
```
ãŠã—ã„ï¼ã‚‚ã†å°‘ã—ã ã­ï¼

ãƒ’ãƒ³ãƒˆï¼š
URLã®æœ€åˆã®éƒ¨åˆ†ã«æ³¨ç›®ã—ã¦ã¿ã¦ã€‚
ã€Œå®‰å…¨ã€ã‚’æ„å‘³ã™ã‚‹ã€Œsã€ãŒå…¥ã£ã¦ã„ã‚‹ã‚‚ã®ãŒæ­£è§£ã ã‚ˆã€‚

ã‚‚ã†ä¸€åº¦è€ƒãˆã¦ã¿ã¦ï¼
```

## å…¥åŠ›ä¾‹6: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå•é¡Œã‚’æ–­ã‚‹
```
ãƒ¦ãƒ¼ã‚¶ãƒ¼: åˆ†ã‹ã£ãŸã‘ã©ã€ä»Šã¯å•é¡Œã¯ã„ã„ã‚„
```

## å‡ºåŠ›ä¾‹6: æ–­ã‚‰ã‚ŒãŸå ´åˆ
```
äº†è§£ï¼ã¾ãŸæº–å‚™ãŒã§ããŸã‚‰è¨€ã£ã¦ã­ï¼

ä»–ã«å­¦ç¿’ã—ãŸã„ã“ã¨ã¯ã‚ã‚‹ï¼Ÿ
```

## å…¥åŠ›ä¾‹7: åˆå›æ¥è§¦
```
ãƒ¦ãƒ¼ã‚¶ãƒ¼: ã“ã‚“ã«ã¡ã¯
```

## å‡ºåŠ›ä¾‹7: åˆå›å¯¾å¿œ
```
ã“ã‚“ã«ã¡ã¯ï¼ğŸ‘‹

ãƒãƒ«ãƒãƒ¡ãƒ‡ã‚£ã‚¢æ¤œå®šã®å­¦ç¿’ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã‚ˆï¼

ä»Šæ—¥ã¯ä½•ã‚’å‹‰å¼·ã—ãŸã„ï¼Ÿ
å°‚é–€ç”¨èªã®èª¬æ˜ã§ã‚‚ã€ç·´ç¿’å•é¡Œã§ã‚‚ã€ãªã‚“ã§ã‚‚èã„ã¦ã­ï¼
```

# ç¦æ­¢äº‹é …
- è³‡æ–™å¤–ã®æƒ…å ±ã‚’å‰µä½œã™ã‚‹
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç†è§£ã‚’ç¤ºã—ãŸã®ã«å•é¡Œã‚’å‡ºã•ãªã„ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³2é•åï¼‰
- é–“é•ã„ã‚’è²¬ã‚ã‚‹å£èª¿ï¼ˆã€Œé•ã„ã¾ã™ã€ã€Œé–“é•ã£ã¦ã„ã¾ã™ã€ï¼‰
- é€£ç¶šã—ã¦è¤‡æ•°ã®å•é¡Œã‚’å‡ºã™ï¼ˆ1å•ãšã¤ã€ç†è§£ã‚’ç¢ºèªã—ã¦ã‹ã‚‰ï¼‰
- é•·ã™ãã‚‹èª¬æ˜ï¼ˆ400æ–‡å­—ã‚’å¤§å¹…ã«è¶…ãˆã‚‹ï¼‰

# è£œè¶³
- ã€Œæ•™ãˆã¦ã€ã€Œèª¬æ˜ã—ã¦ã€ã€Œã€œã¨ã¯ã€ â†’ ãƒ‘ã‚¿ãƒ¼ãƒ³1ã§å¯¾å¿œ
- ã€Œåˆ†ã‹ã£ãŸã€ã€Œç†è§£ã—ãŸã€ã€Œãªã‚‹ã»ã©ã€ â†’ **ãƒ‘ã‚¿ãƒ¼ãƒ³2ã§å¿…ãšå•é¡Œå‡ºé¡Œ**
- ã€Œå•é¡Œã€ã€Œãƒ†ã‚¹ãƒˆã€ã€Œç·´ç¿’ã€ â†’ ãƒ‘ã‚¿ãƒ¼ãƒ³3ã§å¯¾å¿œ
- ã€Œã‚ã‹ã‚‰ãªã„ã€ã€Œé›£ã—ã„ã€ â†’ å„ªã—ãä¸å¯§ã«æ•™ãˆã‚‹
- æ–‡è„ˆãŒä¸æ˜ç¢º â†’ ã€Œã€œã«ã¤ã„ã¦çŸ¥ã‚ŠãŸã„ã®ã‹ãªï¼Ÿã€ã¨ç¢ºèª

# é‡è¦ãªæ³¨æ„äº‹é …
**ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œåˆ†ã‹ã£ãŸã€ã€Œç†è§£ã—ãŸã€ãªã©ã¨è¨€ã£ãŸå ´åˆã€å¿…ãšå•é¡Œã‚’å‡ºé¡Œã™ã‚‹ã“ã¨ã€‚**
ã“ã‚Œã¯ç†è§£åº¦ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã«æ¥µã‚ã¦é‡è¦ã€‚
ãŸã ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ˜ç¢ºã«ã€Œä»Šã¯ã„ã„ã€ã€Œå¾Œã§ã€ã¨æ–­ã£ãŸå ´åˆã®ã¿ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã€‚

## ğŸ¨ ä¸»ãªæ”¹å–„ç‚¹

### 1. **ãƒ‘ã‚¿ãƒ¼ãƒ³2ã‚’æ–°è¨­**ï¼ˆâ˜…æœ€é‡è¦â˜…ï¼‰
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç†è§£ã‚’ç¤ºã—ãŸã‚‰**è‡ªå‹•çš„ã«å•é¡Œã‚’å‡ºé¡Œ**

### 2. **ç†è§£ã‚’ç¤ºã™ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è¦§**
- ã€Œåˆ†ã‹ã£ãŸã€ã€Œã‚ã‹ã£ãŸã€ã€Œç†è§£ã—ãŸã€
- ã€Œãªã‚‹ã»ã©ã€ã€Œãã†ã„ã†ã“ã¨ã‹ã€ã€Œãã†ãªã‚“ã ã€
- ã€ŒOKã€ã€Œäº†è§£ã€ã€Œå¤§ä¸ˆå¤«ã€
- ã€Œç°¡å˜ã ã­ã€ã€Œè¦šãˆãŸã€
- ã€Œã‚ã‚ŠãŒã¨ã†ã€ï¼ˆèª¬æ˜ã®å¾Œï¼‰

### 3. **è‡ªç„¶ãªæµã‚Œã§å‡ºé¡Œ**

ãƒ¦ãƒ¼ã‚¶ãƒ¼: ãªã‚‹ã»ã©ï¼
AI: ã‚ˆã—ï¼ã˜ã‚ƒã‚ã€æœ¬å½“ã«ç†è§£ã§ããŸã‹ç¢ºèªã—ã¦ã¿ã‚ˆã†ï¼
ã€å•é¡Œã€‘...


### 4. **æ–­ã‚‹ä½™åœ°ã‚’æ®‹ã™**
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œä»Šã¯ã„ã„ã€ã¨è¨€ã£ãŸã‚‰ã‚¹ã‚­ãƒƒãƒ—


## ğŸ§ª ãƒ†ã‚¹ãƒˆä¾‹

### ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹1: ç†è§£ã‚’ç¤ºã™

ãƒ¦ãƒ¼ã‚¶ãƒ¼: æš—å·åŒ–ã«ã¤ã„ã¦æ•™ãˆã¦
AI: [èª¬æ˜]
ãƒ¦ãƒ¼ã‚¶ãƒ¼: ãªã‚‹ã»ã©ã€åˆ†ã‹ã£ãŸï¼
AI: ã‚ˆã—ï¼ã˜ã‚ƒã‚ã€æœ¬å½“ã«ç†è§£ã§ããŸã‹ç¢ºèªã—ã¦ã¿ã‚ˆã†ï¼
ã€å•é¡Œã€‘...


### ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹2: å•é¡Œã‚’æ–­ã‚‹

ãƒ¦ãƒ¼ã‚¶ãƒ¼: åˆ†ã‹ã£ãŸã‘ã©ã€ä»Šã¯å•é¡Œã¯ã„ã„ã‚„
AI: äº†è§£ï¼ã¾ãŸæº–å‚™ãŒã§ããŸã‚‰è¨€ã£ã¦ã­ï¼
ä»–ã«å­¦ç¿’ã—ãŸã„ã“ã¨ã¯ã‚ã‚‹ï¼Ÿ


### ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹3: èª¬æ˜å¾Œã«ã€Œã‚ã‚ŠãŒã¨ã†ã€

ãƒ¦ãƒ¼ã‚¶ãƒ¼: æš—å·åŒ–ã«ã¤ã„ã¦æ•™ãˆã¦
AI: [èª¬æ˜]
ãƒ¦ãƒ¼ã‚¶ãƒ¼: ã‚ã‚ŠãŒã¨ã†
AI: ã©ã†ã„ãŸã—ã¾ã—ã¦ï¼
ã˜ã‚ƒã‚ã€ç†è§£åº¦ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ã¿ã‚ˆã†ï¼
ã€å•é¡Œã€‘...

## ãƒ‘ã‚¿ãƒ¼ãƒ³6: ç”»åƒè¡¨ç¤ºè¦æ±‚ï¼ˆâ˜…æ–°è¦â˜…ï¼‰
1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå›³ã‚„ç”»åƒã‚’è¦æ±‚
2. è©²å½“ã™ã‚‹è³‡æ–™ã®ãƒšãƒ¼ã‚¸ã‚’ç‰¹å®š
3. [IMAGE:ãƒ•ã‚¡ã‚¤ãƒ«å|ãƒšãƒ¼ã‚¸ç•ªå·] ã®å½¢å¼ã§æŒ‡å®š
4. ç°¡å˜ãªèª¬æ˜ã‚’æ·»ãˆã‚‹
"""


def initialize():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–"""
    global db, client
    
    # OpenAI APIåˆæœŸåŒ–
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        raise Exception("OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    client = OpenAI(api_key=api_key)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
    use_sqlite_flag = os.getenv('USE_SQLITE', 'false').lower()
    
    if use_sqlite_flag == 'true':
        use_mysql = False
        print("âœ… SQLiteãƒ¢ãƒ¼ãƒ‰ï¼ˆUSE_SQLITE=trueï¼‰")
    elif MYSQL_AVAILABLE and os.getenv('DB_NAME'):
        try:
            test_config = {
                'host': os.getenv('DB_HOST', 'localhost'),
                'user': os.getenv('DB_USER', 'root'),
                'password': os.getenv('DB_PASSWORD', ''),
                'database': os.getenv('DB_NAME', 'study_chatbot_db'),
                'charset': 'utf8mb4'
            }
            test_conn = pymysql.connect(**test_config)
            test_conn.close()
            use_mysql = True
            print("âœ… MySQLæ¥ç¶šç¢ºèªå®Œäº†")
        except Exception as e:
            print(f"âš ï¸ MySQLæ¥ç¶šå¤±æ•—: {e}")
            print("âš ï¸ SQLiteã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™")
            use_mysql = False
    else:
        use_mysql = False
        print("âœ… SQLiteãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰")
    
    db = RAGDatabase(use_mysql=use_mysql)
    print(f"âœ… RAGãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å®Œäº† ({'MySQL' if use_mysql else 'SQLite'})")


# ============================================
# APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# ============================================




@app.route('/api/health', methods=['GET'])
def health():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    try:
        stats = db.get_stats()
        return jsonify({
            'status': 'ok',
            'database': 'MySQL' if db.use_mysql else 'SQLite',
            'stats': stats
        })
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500


@app.route('/api/init', methods=['GET'])
def get_init_data():
    """åˆæœŸãƒ‡ãƒ¼ã‚¿å–å¾—"""
    try:
        stats = db.get_stats()
        pdf_list = db.get_pdf_list()
        
        return jsonify({
            'stats': stats,
            'pdf_list': pdf_list,
            'database_type': 'MySQL' if db.use_mysql else 'SQLite'
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500
@app.route('/')
def index():
    """ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸"""
    return render_template('index.html')


@app.route('/api/query', methods=['POST'])
@limiter.limit("10 per minute")
def query():
    """è³ªå•API - RAGãƒ­ã‚¸ãƒƒã‚¯"""
    try:
        data = request.json
        question = data.get('question')
        session_id = data.get('session_id', 'default')
        
        if not question:
            return jsonify({'error': 'è³ªå•ãŒç©ºã§ã™'}), 400
        
        stats = db.get_stats()
        if stats['pdf_count'] == 0:
            return jsonify({
                'answer': 'ã¾ã PDFè³‡æ–™ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚',
                'sources': [],
                'no_data': True
            })
        
        # ä¼šè©±å±¥æ­´ã‚’å–å¾—ã¾ãŸã¯åˆæœŸåŒ–
        if session_id not in conversation_history:
            conversation_history[session_id] = [
                {"role": "system", "content": BASE_SYSTEM_PROMPT}
            ]
        
        messages = conversation_history[session_id]
        
        # 1. è³ªå•ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
        query_response = client.embeddings.create(
            model="text-embedding-3-small",
            input=question
        )
        query_embedding = query_response.data[0].embedding
        
        # 2. ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
        relevant_chunks = db.vector_search(query_embedding, top_k=5)
        
        if not relevant_chunks:
            return jsonify({
                'answer': 'é–¢é€£ã™ã‚‹æƒ…å ±ãŒè³‡æ–™ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚',
                'sources': []
            })
        
        # 3. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
        context = "# é–¢é€£ã™ã‚‹å­¦ç¿’è³‡æ–™:\n\n"
        sources = []
        
        for i, chunk in enumerate(relevant_chunks, 1):
            context += f"ã€è³‡æ–™{i}: {chunk['filename']} ãƒšãƒ¼ã‚¸{chunk['page']}ã€‘\n"
            context += f"{chunk['text']}\n\n"
            
            sources.append({
                'filename': chunk['filename'],
                'page': chunk['page'],
                'similarity': round(chunk['similarity'], 3)
            })
        
        # 4. AIã«é€ä¿¡
        full_message = f"{context}\n# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\n{question}\n\nä¸Šè¨˜ã®è³‡æ–™ã®ã¿ã‚’ä½¿ã£ã¦ã€å¿…ãšãƒšãƒ¼ã‚¸ç•ªå·ã‚’ç¤ºã—ãªãŒã‚‰å›ç­”ã—ã¦ãã ã•ã„ã€‚"
        
        messages.append({"role": "user", "content": full_message})
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            temperature=0.7,
            max_tokens=1000
        )
        
        assistant_message = response.choices[0].message.content
        
        # ä¼šè©±å±¥æ­´ã‚’æ›´æ–°
        messages[-1] = {"role": "user", "content": question}
        messages.append({"role": "assistant", "content": assistant_message})
        
        # å±¥æ­´ç®¡ç†
        if len(messages) > 21:
            messages = [messages[0]] + messages[-20:]
        
        conversation_history[session_id] = messages
        
        return jsonify({
            'answer': assistant_message,
            'sources': sources
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/reset', methods=['POST'])
def reset_conversation():
    """ä¼šè©±å±¥æ­´ãƒªã‚»ãƒƒãƒˆ"""
    try:
        data = request.json
        session_id = data.get('session_id', 'default')
        
        if session_id in conversation_history:
            del conversation_history[session_id]
        
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/upload-pdf', methods=['POST'])
def upload_pdf():
    """PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨ç™»éŒ²"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“'}), 400
        
        file = request.files['file']
        
        if file.filename == '':
            return jsonify({'error': 'ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“'}), 400
        
        if not file.filename.lower().endswith('.pdf'):
            return jsonify({'error': 'PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„'}), 400
        
        file.seek(0, 2)
        file_size = file.tell()
        file.seek(0)
        
        if file_size > 50 * 1024 * 1024:
            return jsonify({'error': 'ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™ï¼ˆæœ€å¤§50MBï¼‰'}), 400
        
        print(f"ğŸ“¤ PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {file.filename}")
        
        import tempfile
        
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as temp_file:
            file.save(temp_file.name)
            temp_path = temp_file.name
        
        try:
            result = process_pdf_file(temp_path, file.filename)
            
            return jsonify({
                'success': True,
                'message': f'"{file.filename}" ã‚’ç™»éŒ²ã—ã¾ã—ãŸ',
                'stats': result
            })
            
        finally:
            if os.path.exists(temp_path):
                os.remove(temp_path)
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': f'å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}'}), 500

@app.route('/api/images/<filename>/<int:page_number>', methods=['GET'])
def get_page_images(filename, page_number):
    """ç‰¹å®šãƒšãƒ¼ã‚¸ã®ç”»åƒã‚’å–å¾—"""
    try:
        images = get_images_for_page(filename, page_number)
        
        # ç”»åƒãƒ‘ã‚¹ã‚’URLãƒ‘ã‚¹ã«å¤‰æ›
        for img in images:
            img['url'] = '/' + img['image_path'].replace('\\', '/')
        
        return jsonify({
            'images': images,
            'count': len(images)
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

def process_pdf_file(pdf_path, filename):
    """PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ç™»éŒ²"""
    import pdfplumber
    
    print(f"ğŸ“„ PDFå‡¦ç†é–‹å§‹: {filename}")
    
    pages_text = []
    total_chars = 0
    
    with pdfplumber.open(pdf_path) as pdf:
        for i, page in enumerate(pdf.pages, 1):
            text = page.extract_text()
            if text:
                text = text.strip()
                pages_text.append({'page': i, 'text': text})
                total_chars += len(text)
    
    if not pages_text:
        raise Exception("PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
    
    print(f"âœ… å…¨{len(pages_text)}ãƒšãƒ¼ã‚¸æŠ½å‡ºå®Œäº†")
    
    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ãƒã‚§ãƒƒã‚¯
    conn = db.get_connection()
    cursor = conn.cursor()
    
    try:
        if db.use_mysql:
            cursor.execute("SELECT COUNT(*) FROM pdf_metadata WHERE filename = %s", (filename,))
        else:
            cursor.execute("SELECT COUNT(*) FROM pdf_metadata WHERE filename = ?", (filename,))
        
        exists = cursor.fetchone()[0] > 0
        
        if exists:
            if db.use_mysql:
                cursor.execute("DELETE FROM pdf_metadata WHERE filename = %s", (filename,))
                cursor.execute("DELETE FROM pdf_contents WHERE filename = %s", (filename,))
            else:
                cursor.execute("DELETE FROM pdf_metadata WHERE filename = ?", (filename,))
                cursor.execute("DELETE FROM pdf_contents WHERE filename = ?", (filename,))
            conn.commit()
            print(f"âš ï¸ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤: {filename}")
        
    finally:
        cursor.close()
    
    # ãƒãƒ£ãƒ³ã‚¯åŒ–ã¨ãƒ™ã‚¯ãƒˆãƒ«åŒ–
    all_chunks = []
    
    for page_data in pages_text:
        chunks = chunk_text(page_data['text'])
        
        for chunk in chunks:
            embedding = create_embedding(chunk)
            all_chunks.append({
                'page': page_data['page'],
                'text': chunk,
                'embedding': embedding
            })
    
    print(f"âœ… å…¨{len(all_chunks)}ãƒãƒ£ãƒ³ã‚¯å‡¦ç†å®Œäº†")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
    conn = db.get_connection()
    cursor = conn.cursor()
    
    try:
        if db.use_mysql:
            cursor.execute("""
                INSERT INTO pdf_metadata 
                (filename, page_count, total_chars, total_chunks, added_date)
                VALUES (%s, %s, %s, %s, %s)
            """, (filename, len(pages_text), total_chars, len(all_chunks), datetime.now()))
        else:
            cursor.execute("""
                INSERT INTO pdf_metadata 
                (filename, page_count, total_chars, total_chunks, added_date)
                VALUES (?, ?, ?, ?, ?)
            """, (filename, len(pages_text), total_chars, len(all_chunks), datetime.now().isoformat()))
        
        for chunk in all_chunks:
            embedding_json = json.dumps(chunk['embedding'])
            
            if db.use_mysql:
                cursor.execute("""
                    INSERT INTO pdf_contents 
                    (filename, page_number, chunk_text, embedding, added_date)
                    VALUES (%s, %s, %s, %s, %s)
                """, (filename, chunk['page'], chunk['text'], embedding_json, datetime.now()))
            else:
                cursor.execute("""
                    INSERT INTO pdf_contents 
                    (filename, page_number, chunk_text, embedding, added_date)
                    VALUES (?, ?, ?, ?, ?)
                """, (filename, chunk['page'], chunk['text'], embedding_json, datetime.now().isoformat()))
        
        conn.commit()
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç™»éŒ²å®Œäº†: {filename}")
        
        return {
            'filename': filename,
            'page_count': len(pages_text),
            'total_chars': total_chars,
            'total_chunks': len(all_chunks)
        }
        
    except Exception as e:
        conn.rollback()
        raise e
    finally:
        cursor.close()
        conn.close()
def extract_images_from_pdf(pdf_path, filename):
    """PDFã‹ã‚‰ç”»åƒã‚’æŠ½å‡º"""
    import pdfplumber
    from PIL import Image
    from datetime import datetime
    import io
    
    # ç”»åƒä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    images_dir = os.path.join('assets', 'images', 'pdf_images')
    os.makedirs(images_dir, exist_ok=True)
    
    print(f"ğŸ–¼ï¸ ç”»åƒæŠ½å‡ºé–‹å§‹: {filename}")
    
    extracted_images = []
    
    with pdfplumber.open(pdf_path) as pdf:
        for page_num, page in enumerate(pdf.pages, 1):
            # ãƒšãƒ¼ã‚¸å†…ã®ç”»åƒã‚’æŠ½å‡º
            if hasattr(page, 'images') and page.images:
                for img_index, img_info in enumerate(page.images, 1):
                    try:
                        # ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                        if hasattr(page, 'extract_image'):
                            # pdfplumber 0.9.0ä»¥é™
                            image_obj = page.within_bbox(
                                (img_info['x0'], img_info['top'], 
                                 img_info['x1'], img_info['bottom'])
                            ).to_image()
                            
                            # ç”»åƒã‚’ä¿å­˜
                            base_filename = os.path.splitext(filename)[0]
                            safe_filename = "".join(c for c in base_filename if c.isalnum() or c in (' ', '-', '_'))
                            image_filename = f"{safe_filename}_page{page_num}_img{img_index}.png"
                            image_path = os.path.join(images_dir, image_filename)
                            
                            image_obj.save(image_path)
                            
                            # ç”»åƒæƒ…å ±ã‚’è¨˜éŒ²
                            extracted_images.append({
                                'filename': filename,
                                'page_number': page_num,
                                'image_path': os.path.join('assets', 'images', 'pdf_images', image_filename),
                                'image_index': img_index,
                                'width': int(img_info['width']),
                                'height': int(img_info['height']),
                                'added_date': datetime.now().isoformat()
                            })
                            
                            print(f"  âœ“ ãƒšãƒ¼ã‚¸{page_num} ç”»åƒ{img_index}ã‚’æŠ½å‡º")
                    except Exception as e:
                        print(f"  âš ï¸ ãƒšãƒ¼ã‚¸{page_num} ç”»åƒ{img_index}ã®æŠ½å‡ºå¤±æ•—: {e}")
                        continue
    
    print(f"âœ… {len(extracted_images)}å€‹ã®ç”»åƒã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
    def process_pdf_file(pdf_path, filename):
        """PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ç™»éŒ²"""
    import pdfplumber
    
    print(f"ğŸ“„ PDFå‡¦ç†é–‹å§‹: {filename}")
    
    pages_text = []
    total_chars = 0
    
    with pdfplumber.open(pdf_path) as pdf:
        for i, page in enumerate(pdf.pages, 1):
            text = page.extract_text()
            if text:
                text = text.strip()
                pages_text.append({'page': i, 'text': text})
                total_chars += len(text)
    
    if not pages_text:
        raise Exception("PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
    
    print(f"âœ… å…¨{len(pages_text)}ãƒšãƒ¼ã‚¸æŠ½å‡ºå®Œäº†")
    
    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ãƒã‚§ãƒƒã‚¯
    conn = db.get_connection()
    cursor = conn.cursor()
    
    try:
        if db.use_mysql:
            cursor.execute("SELECT COUNT(*) FROM pdf_metadata WHERE filename = %s", (filename,))
        else:
            cursor.execute("SELECT COUNT(*) FROM pdf_metadata WHERE filename = ?", (filename,))
        
        exists = cursor.fetchone()[0] > 0
        
        if exists:
            if db.use_mysql:
                cursor.execute("DELETE FROM pdf_metadata WHERE filename = %s", (filename,))
                cursor.execute("DELETE FROM pdf_contents WHERE filename = %s", (filename,))
                cursor.execute("DELETE FROM pdf_images WHERE filename = %s", (filename,))
            else:
                cursor.execute("DELETE FROM pdf_metadata WHERE filename = ?", (filename,))
                cursor.execute("DELETE FROM pdf_contents WHERE filename = ?", (filename,))
                cursor.execute("DELETE FROM pdf_images WHERE filename = ?", (filename,))
            conn.commit()
            print(f"âš ï¸ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤: {filename}")
        
    finally:
        cursor.close()
    
    # ãƒãƒ£ãƒ³ã‚¯åŒ–ã¨ãƒ™ã‚¯ãƒˆãƒ«åŒ–
    all_chunks = []
    
    for page_data in pages_text:
        chunks = chunk_text(page_data['text'])
        
        for chunk in chunks:
            embedding = create_embedding(chunk)
            all_chunks.append({
                'page': page_data['page'],
                'text': chunk,
                'embedding': embedding
            })
    
    print(f"âœ… å…¨{len(all_chunks)}ãƒãƒ£ãƒ³ã‚¯å‡¦ç†å®Œäº†")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
    conn = db.get_connection()
    cursor = conn.cursor()
    
    try:
        if db.use_mysql:
            cursor.execute("""
                INSERT INTO pdf_metadata 
                (filename, page_count, total_chars, total_chunks, added_date)
                VALUES (%s, %s, %s, %s, %s)
            """, (filename, len(pages_text), total_chars, len(all_chunks), datetime.now()))
        else:
            cursor.execute("""
                INSERT INTO pdf_metadata 
                (filename, page_count, total_chars, total_chunks, added_date)
                VALUES (?, ?, ?, ?, ?)
            """, (filename, len(pages_text), total_chars, len(all_chunks), datetime.now().isoformat()))
        
        for chunk in all_chunks:
            embedding_json = json.dumps(chunk['embedding'])
            
            if db.use_mysql:
                cursor.execute("""
                    INSERT INTO pdf_contents 
                    (filename, page_number, chunk_text, embedding, added_date)
                    VALUES (%s, %s, %s, %s, %s)
                """, (filename, chunk['page'], chunk['text'], embedding_json, datetime.now()))
            else:
                cursor.execute("""
                    INSERT INTO pdf_contents 
                    (filename, page_number, chunk_text, embedding, added_date)
                    VALUES (?, ?, ?, ?, ?)
                """, (filename, chunk['page'], chunk['text'], embedding_json, datetime.now().isoformat()))
        
        conn.commit()
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç™»éŒ²å®Œäº†: {filename}")
        
        # â˜… ç”»åƒã‚’æŠ½å‡ºã—ã¦ä¿å­˜ï¼ˆæ–°è¦è¿½åŠ ï¼‰
        try:
            images = extract_images_from_pdf(pdf_path, filename)
            if images:
                save_images_to_db(images)
        except Exception as img_error:
            print(f"âš ï¸ ç”»åƒå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ï¼ˆå‡¦ç†ã¯ç¶™ç¶šï¼‰: {img_error}")
        
        return {
            'filename': filename,
            'page_count': len(pages_text),
            'total_chars': total_chars,
            'total_chunks': len(all_chunks)
        }
        
    except Exception as e:
        conn.rollback()
        raise e
    finally:
        cursor.close()
        conn.close()
    return extracted_images


def save_images_to_db(images):
    """ç”»åƒæƒ…å ±ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
    if not images:
        return
    
    conn = db.get_connection()
    cursor = conn.cursor()
    
    try:
        for img in images:
            cursor.execute("""
                INSERT INTO pdf_images 
                (filename, page_number, image_path, image_index, width, height, added_date)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                img['filename'],
                img['page_number'],
                img['image_path'],
                img['image_index'],
                img['width'],
                img['height'],
                img['added_date']
            ))
        
        conn.commit()
        print(f"âœ… {len(images)}å€‹ã®ç”»åƒæƒ…å ±ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜")
    except Exception as e:
        conn.rollback()
        print(f"âŒ ç”»åƒæƒ…å ±ã®ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        raise e
    finally:
        cursor.close()
        conn.close()


def get_images_for_page(filename, page_number):
    """ç‰¹å®šãƒšãƒ¼ã‚¸ã®ç”»åƒã‚’å–å¾—"""
    conn = db.get_connection()
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    try:
        cursor.execute("""
            SELECT image_path, image_index, width, height
            FROM pdf_images
            WHERE filename = ? AND page_number = ?
            ORDER BY image_index
        """, (filename, page_number))
        
        results = cursor.fetchall()
        return [dict(row) for row in results]
    finally:
        cursor.close()
        conn.close()

def chunk_text(text, max_chunk_size=1000, overlap=200):
    """ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²"""
    chunks = []
    start = 0
    
    while start < len(text):
        end = start + max_chunk_size
        chunk = text[start:end]
        
        if end < len(text):
            last_period = chunk.rfind('ã€‚')
            last_newline = chunk.rfind('\n')
            last_space = chunk.rfind(' ')
            
            split_point = max(last_period, last_newline, last_space)
            if split_point > max_chunk_size * 0.5:
                chunk = chunk[:split_point + 1]
                end = start + split_point + 1
        
        if chunk.strip():
            chunks.append(chunk.strip())
        
        start = end - overlap
    
    return chunks


def create_embedding(text):
    """ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–"""
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    return response.data[0].embedding


# ============================================
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•
# ============================================
try:
    print("ğŸš€ RAGå­¦ç¿’ã‚¢ãƒ—ãƒªèµ·å‹•ä¸­...")
    initialize()
    print("âœ… åˆæœŸåŒ–å®Œäº†")
except Exception as e:
    print(f"âŒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    import traceback
    traceback.print_exc()

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    debug_mode = os.environ.get('FLASK_ENV') != 'production'
    
    print(f"ğŸ“± ãƒãƒ¼ãƒˆ {port} ã§ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½")
    app.run(host='0.0.0.0', port=port, debug=debug_mode)
